Fundamentals

Why pick DataBricks?

1. Databricks and Spark offer a **unified platform** 
    - Spark on Databricks combines ETL, stream processing, machine learning, and collaborative notebooks.
    - Data scientists, analysts, and engineers can write Spark code in Python, Scala, SQL, and R.
2. Spark's unified platform is **scalable to petabytes of data and clusters of thousands of nodes**.  
    - The same code written on smaller data sets scales to large workloads, often with only small changes.
2. Spark on Databricks decouples data storage from the compute and query engine.  
    - Spark's query engine **connects to any number of data sources** such as S3, Azure Blob Storage, Redshift, and Kafka.  
    - This **minimizes costs**; a dedicated cluster does not need to be maintained and the compute cluster is **easily updated to the latest version** of Spark.